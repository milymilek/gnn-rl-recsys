{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c54b140-d3be-4ec9-b14b-830f4973ee46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milosz\\Desktop\\python\\thesis-recsys\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"../../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6088f9e4-ec83-4cf4-ae00-daf1ca67ff01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16310455490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import operator\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric import nn\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b1cb33-ac35-48ba-a79e-a767cc484294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ea2e92-6db9-470e-b8e2-95812455cd66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/steam/graph.pkl\", \"rb\") as f:\n",
    "    graph = pickle.load(f)\n",
    "    \n",
    "train_data = graph['train_data']\n",
    "train_loader = graph['train_loader']\n",
    "val_data = graph['valid_data']\n",
    "val_loader = graph['valid_loader']\n",
    "mp_matrix = graph['mp_matrix']\n",
    "val_matrix = graph['val_matrix']\n",
    "\n",
    "n_users, n_items = train_data['user'].x.shape[0], train_data['app'].x.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4752f81-c611-4122-8d20-7cf32599f649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.33)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[('user', 'recommends', 'app')]['edge_label'].to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45258622-1bc7-40aa-9885-ba42db99776b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 0.6645077918728179, 2.0: 0.1796214914887921, 3.0: 0.070225820999041, 4.0: 0.03321006377821784, 5.0: 0.017800771573286255, 6.0: 0.010632202929448099, 7.0: 0.006738467568455037, 8.0: 0.004447421203298246, 9.0: 0.0030941843095606022, 10.0: 0.0021632225429049465, 11.0: 0.001598449940506489, 12.0: 0.0011729140016323624, 13.0: 0.0009277009548635171, 14.0: 0.0007020527788475053, 15.0: 0.0005295558350433574, 16.0: 0.0004369487801466126, 17.0: 0.0003619501089274179, 18.0: 0.0002849949506329399, 19.0: 0.0002249960136575841, 20.0: 0.00018097505446370895, 21.0: 0.0001633666707861589, 22.0: 0.00014478004357096715, 23.0: 0.00010923719503665315, 24.0: 8.967232428381976e-05, 25.0: 8.15202948034725e-05, 26.0: 6.293366758828077e-05, 27.0: 5.9346774616927985e-05, 28.0: 5.282515103265018e-05, 29.0: 3.652109207195568e-05, 30.0: 3.652109207195568e-05, 31.0: 2.6738656695538982e-05, 32.0: 2.5434331978683422e-05, 33.0: 2.510825079946953e-05, 34.0: 2.2825682544972302e-05, 35.0: 2.1521357828116743e-05, 36.0: 1.043459773484448e-05, 37.0: 1.0760678914058371e-05, 38.0: 1.30432471685556e-05, 39.0: 1.30432471685556e-05, 40.0: 1.5977977781480612e-05, 41.0: 7.49986712191947e-06, 42.0: 7.82594830113336e-06, 43.0: 8.80419183877503e-06, 44.0: 7.49986712191947e-06, 45.0: 5.21729886742224e-06, 46.0: 4.23905532978057e-06, 47.0: 6.5216235842778e-06, 48.0: 3.91297415056668e-06, 49.0: 3.58689297135279e-06, 50.0: 2.93473061292501e-06, 51.0: 4.89121768820835e-06, 52.0: 2.93473061292501e-06, 53.0: 2.28256825449723e-06, 54.0: 4.56513650899446e-06, 55.0: 2.93473061292501e-06, 56.0: 4.23905532978057e-06, 57.0: 9.7824353764167e-07, 58.0: 1.95648707528334e-06, 59.0: 1.30432471685556e-06, 60.0: 9.7824353764167e-07, 61.0: 1.30432471685556e-06, 62.0: 9.7824353764167e-07, 63.0: 2.28256825449723e-06, 64.0: 1.63040589606945e-06, 65.0: 1.63040589606945e-06, 66.0: 1.30432471685556e-06, 67.0: 1.63040589606945e-06, 68.0: 6.5216235842778e-07, 69.0: 9.7824353764167e-07, 70.0: 1.95648707528334e-06, 71.0: 6.5216235842778e-07, 72.0: 3.2608117921389e-07, 73.0: 6.5216235842778e-07, 74.0: 6.5216235842778e-07, 75.0: 1.95648707528334e-06, 76.0: 6.5216235842778e-07, 77.0: 3.2608117921389e-07, 78.0: 3.2608117921389e-07, 79.0: 3.2608117921389e-07, 81.0: 1.30432471685556e-06, 83.0: 3.2608117921389e-07, 86.0: 6.5216235842778e-07, 88.0: 3.2608117921389e-07, 90.0: 6.5216235842778e-07, 91.0: 1.30432471685556e-06, 92.0: 6.5216235842778e-07, 95.0: 3.2608117921389e-07, 99.0: 3.2608117921389e-07, 100.0: 3.2608117921389e-07, 104.0: 3.2608117921389e-07, 105.0: 3.2608117921389e-07, 108.0: 3.2608117921389e-07, 111.0: 3.2608117921389e-07, 114.0: 3.2608117921389e-07, 117.0: 3.2608117921389e-07, 118.0: 3.2608117921389e-07, 128.0: 3.2608117921389e-07, 132.0: 3.2608117921389e-07, 150.0: 3.2608117921389e-07, 168.0: 3.2608117921389e-07, 178.0: 3.2608117921389e-07, 195.0: 3.2608117921389e-07, 200.0: 3.2608117921389e-07, 223.0: 3.2608117921389e-07}\n"
     ]
    }
   ],
   "source": [
    "arr = mp_matrix.sum(axis=1).getA()\n",
    "unique_values, counts = np.unique(arr, return_counts=True)\n",
    "normalized_counts = counts / len(arr)\n",
    "\n",
    "# Create a dictionary with normalized value counts\n",
    "value_counts_normalized = {value: count for value, count in zip(unique_values, normalized_counts)}\n",
    "\n",
    "# Print the result\n",
    "print(value_counts_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcb4de2-6119-4ca7-9474-45485d969806",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# real_cols = ['positive_ratio', 'user_reviews', 'price_final', 'price_original', 'discount']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# app_features_norm = scaler.fit_transform(app_features[real_cols].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a5ef34-ea3a-4e1e-b23e-160b41c77b08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataloader:\n",
    "#  - user: x->attributes of sampled nodes, n_id->mapping of sampled nodes to ids from whole graph\n",
    "#  - app: x->attributes of sampled nodes, n_id->mapping of sampled nodes to ids from whole graph\n",
    "#  - (user recommends app): \n",
    "#      edge_index -> sampled edges with batch ids with neighbors\n",
    "#      edge_label -> labels of edges which will be evaluated, size of batch size\n",
    "#      e_id -> mapping of sampled edges to ids from whole graph, refers to ?????\n",
    "#      input_id -> mapping of sampled edges to ids from whole graph, refers to edge_label_index\n",
    "#      edge_label_index -> edge index, ids of nodes in sampled graph which will be evaluated\n",
    "\n",
    "\n",
    "# To validate nodes first get sampled nodes ids from edge_label_index, then map them to whole graph\n",
    "# using n_ids of user and app and then check if such edge exists in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e776c55a-8ac9-4a99-82d3-efc6511f724f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.SAGEConv((hidden_channels, hidden_channels), hidden_channels, normalize=True)\n",
    "        self.conv2 = nn.SAGEConv((hidden_channels, hidden_channels), out_channels, normalize=False)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user, x_app, edge_label_index):\n",
    "        x_user = x_user[edge_label_index[0]]\n",
    "        x_app = x_app[edge_label_index[1]]\n",
    "        return (x_user * x_app).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, entities, hidden_channels, out_channels, metadata):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_emb = torch.nn.Embedding(entities[0].x.shape[0], hidden_channels)\n",
    "        self.app_emb = torch.nn.Embedding(entities[1].x.shape[0], hidden_channels)\n",
    "        self.app_lin = torch.nn.Linear(entities[1].x.shape[1], hidden_channels)\n",
    "        \n",
    "        self.gnn = GNN(hidden_channels=hidden_channels, out_channels=out_channels)\n",
    "        self.gnn = nn.to_hetero(self.gnn, metadata=metadata, aggr='sum')\n",
    "        \n",
    "        self.clf = Classifier()\n",
    "        \n",
    "    def forward(self, batch):  \n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(batch['user'].n_id),\n",
    "          \"app\": self.app_emb(batch['app'].n_id) + self.app_lin(batch['app'].x),\n",
    "        } \n",
    "        \n",
    "        x_dict = self.gnn(x_dict, batch.edge_index_dict)\n",
    "        pred = self.clf(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"app\"],\n",
    "            batch['user', 'recommends', 'app'].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "    \n",
    "    def evaluate(self, batch):\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(batch['user'].n_id),\n",
    "          \"app\": self.app_emb(batch['app'].n_id) + self.app_lin(batch['app'].x),\n",
    "        } \n",
    "\n",
    "        x_dict = self.gnn(x_dict, batch.edge_index_dict)\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "def xavier_init(m):\n",
    "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch_geometric.nn.dense.linear.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=1.41)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "    \n",
    "model = Model(entities=(train_data['user'], train_data['app']), \n",
    "              hidden_channels=32, out_channels=32, metadata=train_data.metadata())\n",
    "model.apply(xavier_init)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396ceead-7335-4af4-a015-3377d330d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-2)\n",
    "#optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-1, momentum=0.9)\n",
    "optimizer = torch.optim.RMSprop(params=model.parameters(), lr=0.001, momentum=0.9)\n",
    "#writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beb6713e-13af-4409-982a-6c041888c2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(n_epochs=5, print_loss=500):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.\n",
    "        preds, ground_truths = [], []\n",
    "        print(f\"Metrics: {evaluate_nn(model, mp_matrix, val_matrix, k=10)}\")\n",
    "        \n",
    "        for i_batch, batch in enumerate(tqdm(train_loader)):\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            y_pred = model(batch)\n",
    "            y_true = batch['user', 'recommends', 'app'].edge_label\n",
    "            loss = criterion(y_pred, y_true.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            preds.append(y_pred)\n",
    "            ground_truths.append(y_true)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if not ((i_batch+1) % print_loss):\n",
    "                pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "                ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "                last_loss = running_loss / print_loss\n",
    "                #writer.add_scalar(\"Loss/train\", last_loss, epoch*len(train_loader) + i_batch + 1)\n",
    "                train_roc_auc = roc_auc_score(ground_truth, pred)\n",
    "                test_loss, test_roc_auc = test()\n",
    "                \n",
    "                \n",
    "                preds, ground_truths = [], []\n",
    "                running_loss = 0.\n",
    "                \n",
    "                print(f\"batch <{i_batch}>\\ntrain_loss: {last_loss} - train_roc_auc: {train_roc_auc}\\ntest_loss: {test_loss} - test_roc_auc: {test_roc_auc}\\n\")\n",
    "        print(f\"Epoch: {epoch}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e0484a-ca88-43a0-b8ba-5f72241be99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    preds, ground_truths = [], []\n",
    "\n",
    "    for i_batch, batch in enumerate(val_loader):\n",
    "        batch = batch.to(device)\n",
    "        y_pred = model(batch)\n",
    "        y_true = batch['user', 'recommends', 'app'].edge_label\n",
    "        loss = criterion(y_pred, y_true.float())\n",
    "        \n",
    "        preds.append(y_pred)\n",
    "        ground_truths.append(y_true)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    \n",
    "    test_loss = running_loss / len(val_loader)\n",
    "    test_score = roc_auc_score(ground_truth, pred)\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d36edf0-0f8b-4eb2-8a84-e467c4c06af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    bool_2d = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v]).astype(bool)\n",
    "    \n",
    "    prec_k = (reco_relevance.getA().sum(axis=1, where=bool_2d) / v).mean()\n",
    "    return prec_k\n",
    "\n",
    "# def mean_average_prec(reco_relevance):\n",
    "#     K = reco_relevance.shape[1]\n",
    "    \n",
    "#     mean_ap = 0.0\n",
    "#     for k in range(1, K+1):\n",
    "#         mean_ap += prec_k(reco_relevance[:, :k]) # DODAC MNOŻNIK 1/0 GDY ITEM JEST RELEWANTNY!!!\n",
    "#     return mean_ap / K\n",
    "\n",
    "def recall_k(reco_relevance, relevance, k=10):\n",
    "    sum_relevant = relevance.sum(axis=1)\n",
    "    return (reco_relevance.sum(axis=1) / sum_relevant).mean()\n",
    "\n",
    "def ndcg_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    ideal_relevance = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v])\n",
    "    \n",
    "    discount = 1 / np.log2(np.arange(2, k+2))\n",
    "    idcg = (ideal_relevance * discount).sum(axis=1)\n",
    "    dcg = (reco_relevance * discount).sum(axis=1)\n",
    "    ndcg = (dcg / idcg).mean()\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_embeddings(model, data):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    x_dict = model.evaluate(data)\n",
    "    return x_dict\n",
    "\n",
    "@torch.no_grad()\n",
    "def recommend_k(user_emb, item_emb, past_interactions=None, k=10, user_batch_size=1000):\n",
    "    def remove_past_interactions(prob, user_batch):\n",
    "        id_x = np.repeat(np.arange(user_batch.shape[0]), np.diff(past_interactions[user_batch].indptr))\n",
    "        id_y = past_interactions[user_batch].indices\n",
    "        prob[id_x, id_y] = -torch.inf\n",
    "        return prob\n",
    "    \n",
    "    recommended_batches = []\n",
    "    user_batches = torch.arange(user_emb.shape[0]).split(user_batch_size)\n",
    "    for user_batch in user_batches:\n",
    "        prob = (user_emb[user_batch] @ item_emb.T).sigmoid()\n",
    "        prob = remove_past_interactions(prob, user_batch)\n",
    "        recommended_batches.append(prob.topk(k, 1)[1])\n",
    "    \n",
    "    recommendations = torch.cat(recommended_batches, 0)\n",
    "    return recommendations\n",
    "\n",
    "def recommendation_relevance(recommendations, ground_truth):\n",
    "    \"\"\"\n",
    "    Computes the relevance matrix of recommended items based on ground truth data.\n",
    "\n",
    "    This function takes a matrix of recommended items and a ground truth sparse matrix, and calculates\n",
    "    binary relevance of recommended items for each user. The relevance is determined by\n",
    "    comparing the recommended items with the actual items in the ground truth.\n",
    "\n",
    "    Args:\n",
    "        recommendations (numpy.ndarray): A 2D matrix of shape (n_users, k) where k is the number of \n",
    "            recommended items per user. Each row contains indices representing the recommended \n",
    "            items for a user.\n",
    "        ground_truth (scipy.csr_matrix): A sparse matrix of shape (n_users, n_items). The matrix \n",
    "            contains binary values indicating whether an item is relevant (1) or not (0) for each user.\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrix: A 2D matrix of shape (n_users, k) containing the relevance scores of the\n",
    "        recommended items for each user.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions of 'recommendations' and 'ground_truth' do not match or\n",
    "            are incompatible for matrix operations.\n",
    "    \"\"\"\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    k = recommendations.shape[1]\n",
    "    \n",
    "    if recommendations.shape[0] != n_users:\n",
    "        raise ValueError(\"Number of users in 'recommendations' should match 'ground_truth'.\")\n",
    "    \n",
    "    user_idx = np.repeat(np.arange(n_users), k)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, k))  # get values under arrays of indices \n",
    "                                                                        # (user_idx and item_idx) from ground truth\n",
    "    relevance_mask = np.asarray((ground_truth.sum(axis=1) != 0)).ravel()\n",
    "    \n",
    "    return relevance, relevance_mask\n",
    "\n",
    "def evaluate_nn(model, mp_matrix, val_matrix, k):\n",
    "    x_emb = generate_embeddings(model, val_data)\n",
    "    recommendations = recommend_k(x_emb['user'], x_emb['app'], past_interactions=mp_matrix, \n",
    "                                  k=10, user_batch_size=10000).cpu().numpy()\n",
    "    reco_relevance, relevance_mask = recommendation_relevance(recommendations, val_matrix)\n",
    "    \n",
    "    prec_k = precision_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    rec_k = recall_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    n_k = ndcg_k(reco_relevance[relevance_mask].getA(), val_matrix[relevance_mask], k)\n",
    "\n",
    "    return {f\"precision@{k}\": prec_k, f\"recall@{k}\": rec_k, f\"ndcg@{k}\": n_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb22f31f-8615-4b86-b9ff-048de3a7789e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'precision@10': 4.879985029589232e-06, 'recall@10': 6.4982465e-05, 'ndcg@10': 3.0109065902944535e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████████▌                                                                                                                                                                                                                    | 30/538 [01:17<2:43:01, 19.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <29>\n",
      "train_loss: 0.5383076419432958 - train_roc_auc: 0.7507279210620457\n",
      "test_loss: 0.48262545558014097 - test_roc_auc: 0.8307612005875952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████████████████                                                                                                                                                                                                        | 60/538 [02:34<2:33:53, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <59>\n",
      "train_loss: 0.4725937952597936 - train_roc_auc: 0.8262756432427301\n",
      "test_loss: 0.45927878580194836 - test_roc_auc: 0.8417856576795845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████████████████████▋                                                                                                                                                                                           | 90/538 [03:51<2:22:47, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <89>\n",
      "train_loss: 0.47331492602825165 - train_roc_auc: 0.8237963400946723\n",
      "test_loss: 0.46242282344094404 - test_roc_auc: 0.8413468707362421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████████████████████████████▉                                                                                                                                                                              | 120/538 [05:08<2:14:19, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <119>\n",
      "train_loss: 0.4579842001199722 - train_roc_auc: 0.8398552401860555\n",
      "test_loss: 0.4474266977456726 - test_roc_auc: 0.8494228498550564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                                 | 150/538 [06:25<2:03:39, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <149>\n",
      "train_loss: 0.4500217060248057 - train_roc_auc: 0.8463977779282463\n",
      "test_loss: 0.45129380426226495 - test_roc_auc: 0.854573725029717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                     | 180/538 [07:42<1:54:33, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <179>\n",
      "train_loss: 0.4470713406801224 - train_roc_auc: 0.847934163676368\n",
      "test_loss: 0.4394587393911736 - test_roc_auc: 0.8578322589816852\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                        | 210/538 [08:58<1:44:04, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <209>\n",
      "train_loss: 0.4450747221708298 - train_roc_auc: 0.8495352403322856\n",
      "test_loss: 0.4343484247688988 - test_roc_auc: 0.8616533412919662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                            | 240/538 [10:16<1:36:15, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <239>\n",
      "train_loss: 0.44427080551783243 - train_roc_auc: 0.8501900421248543\n",
      "test_loss: 0.43366842348806683 - test_roc_auc: 0.8608439688625563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 270/538 [11:33<1:25:33, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <269>\n",
      "train_loss: 0.443132479985555 - train_roc_auc: 0.8507302549150255\n",
      "test_loss: 0.4309441326780522 - test_roc_auc: 0.8619172310378662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 300/538 [12:52<1:19:02, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <299>\n",
      "train_loss: 0.4326171676317851 - train_roc_auc: 0.8592321205139161\n",
      "test_loss: 0.42995265154410195 - test_roc_auc: 0.8635502659336327\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 329/538 [13:34<08:37,  2.48s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(n_epochs=5, print_loss=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4564b6a9-5c89-4b59-a4aa-5ab8de121892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision@10': 0.002974831189021801,\n",
       " 'recall@10': 0.02160505,\n",
       " 'ndcg@10': 0.010332927884803004}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_nn(model, mp_matrix, val_matrix, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ad1dd-88ba-419b-8806-f2ddd52983ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5307c5-a382-40ba-a63e-6d759454e5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2 = retrieval.RetrievalPrecision(top_k=5)\n",
    "r2 = retrieval.RetrievalRecall(top_k=2)\n",
    "ndcg = retrieval.RetrievalNormalizedDCG(top_k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b076e-2231-433b-8cc1-b16baceb8dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = torch.tensor([0.7, 0.8, 0.1, 0.2, 0.4, 0.6, 0.5, 0.9, 0.3, 0.15])\n",
    "targets = torch.tensor([True, True, False, False, False, False, False, False, False, False])\n",
    "indices = torch.tensor([0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "mask = torch.ones(preds.shape, dtype=torch.bool)\n",
    "mask[[4, 5, 7]] = False\n",
    "print(preds[mask])\n",
    "print(targets[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5112db0-910d-41ca-a474-9309bbdd820f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = torch.tensor([1.0, 0.85, 0.8, 0.7, 0.65])\n",
    "targets = torch.tensor([False, False, False, False, False])\n",
    "indices = torch.tensor([0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dffbad-516c-44c2-b2cf-59c87945d97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2(preds, targets, indexes=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36301e-fd1c-4736-85ba-c21c0f9768bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2(preds, targets, indexes=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337d182-dfa6-49f9-ab1f-4ca29816908a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndcg(preds, targets, indexes=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ad60d-43c0-4464-a4f5-33fdbdec5023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dcg(rel):\n",
    "    g = 0.\n",
    "    for i in range(1,6):\n",
    "        g+= (2**rel[i-1] - 1)/np.log2(i+1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd36c4-f19c-42d9-9a30-ce5a18d6a117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rel = [1,0,1,0,1]\n",
    "rel_idcg = [1,1,1,0,0]\n",
    "print(dcg(rel))\n",
    "print(dcg(rel_idcg))\n",
    "print(dcg(rel)/dcg(rel_idcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210302d-0aa8-4a66-98c2-6d9a28b9484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0.9, 0.7, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88e770-5ae4-42d3-8c02-bed10ddc5dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(preds[i][:3] / torch.log2(torch.arange(3)+2)).sum() / (torch.tensor([0.9, 0.7, 0.6]) / torch.log2(torch.arange(3)+2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c4421-a44b-4197-8b7e-eb54db214a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1922d-4623-4597-935f-f78c618f64bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.log2(torch.arange(3)+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba09046-a518-439c-9c99-30a55fd84050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceef365-2ccb-41b4-9171-a64418858fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e038ff8-6486-4469-bc94-7803c0e434d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy().round())\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ad13-b1ce-4dfd-b004-cbacd7489344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(path):\n",
    "    model = Model(hidden_channels=32, out_channels=32, metadata=train_data.metadata())\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b149d4-46b6-4bc4-8559-130ae2b93545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save_model(model, \"models/gnn_03.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d26e9-9234-474a-8cd4-8ade83aba18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model(\"models/gnn_03.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbd4af-954d-4dc7-9c6d-9352138dc066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(nn.summary(model, next(iter(train_loader)).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f847e7-0424-471d-b78c-0bdff124cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fcdc9-222c-4488-9b23-43057a14361f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
