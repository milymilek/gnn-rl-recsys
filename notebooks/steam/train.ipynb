{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a88688-5214-4ead-a060-4df9633efd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milosz\\thesis-recsys\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"../../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b41f0f27-4278-4c12-845c-2655b9edcad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2abc5d877d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import operator\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from models import NCF, DeepFM\n",
    "from features.store import FeatureStore\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec6ccb1-bebd-4890-adb6-64417a22ed65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf866f5-a4f6-46bf-aa40-3fc38e3d5e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/steam/data.pkl\", \"rb\") as f:\n",
    "    data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cde4358-ccb4-43cb-83fc-a3f4a6b76ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = data['relations_datastore'].dataframe.train.values.T\n",
    "supervision_set = data['relations_datastore'].dataframe.supervision.values.T\n",
    "valid_set = data['relations_datastore'].dataframe.valid.values.T\n",
    "item_attr = data['items_datastore'].dataframe.df\n",
    "user_attr = data['users_datastore'].dataframe.df\n",
    "\n",
    "scheme_relations = data['relations_datastore'].scheme\n",
    "scheme_items = data['items_datastore'].scheme\n",
    "scheme_users = data['users_datastore'].scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af3050cf-12a6-4f11-9dbc-24e83cfcff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0,  699164,  699171, ..., 3017741, 3017981, 3017274],\n",
       "       [      0,       0,       0, ...,    1230,    1230,    1230]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e556573-600e-4ee0-a615-02fed12699a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1518288, 1274242, 2584398, ..., 3040549, 2142738, 1548244],\n",
       "       [      0,       0,       0, ...,    1229,    1229,    1229]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervision_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887e116-8bd2-4a81-86e8-0f2a18bafa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1371cf46-89fc-4a89-94bf-e69421bcfd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0,  699164,  699171, ..., 3040549, 2142738, 1548244],\n",
       "       [      0,       0,       0, ...,    1229,    1229,    1229]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((train_set, supervision_set), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbb8cb8-e9f7-454f-a251-140accc5109c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/steam/matrix.pkl\", \"rb\") as f:\n",
    "    matrix = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7587b6d6-5aac-4457-bbd7-a3e7e1275347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_matrix = matrix['train_csr']\n",
    "val_matrix = matrix['valid_csr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec240adc-0d43-4a65-b58c-16f2e5174f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scaler_user = StandardScaler()\n",
    "# user_attr_preprocess = scaler_user.fit_transform(user_attr)\n",
    "\n",
    "# scaler_item = StandardScaler()\n",
    "# item_attr_preprocess = np.copy(item_attr)\n",
    "# item_attr_preprocess[:, 435:] = scaler_item.fit_transform(item_attr[:, 435:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcfa3ae-faa4-4a05-b55c-bb529685fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        run_time = end_time - start_time\n",
    "        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31739385-daee-4693-ad46-180eb9c775d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepFMDataset(Dataset):\n",
    "    def __init__(self, feature_store, edge_index, user_attr, item_attr, neg_sampl):\n",
    "        self.edge_index = torch.tensor(edge_index) + 1\n",
    "        self.user_attr = torch.tensor(user_attr.values)\n",
    "        self.item_attr = feature_store.attr2tensor(item_attr, scheme='item_feat')\n",
    "        \n",
    "        self.users = self.edge_index[:, 0]\n",
    "        self.items = self.edge_index[:, 1]\n",
    "\n",
    "        self.n_users = self.user_attr.shape[0]\n",
    "        self.n_items = self.item_attr.shape[0]\n",
    "\n",
    "        self.neg_sampl = neg_sampl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_index.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        u_id = self.users[idx].repeat(self.neg_sampl + 1)\n",
    "        i_id = torch.cat([self.items[idx].unsqueeze(0), self._approx_neg_sampl()])\n",
    "        \n",
    "        u_attr = self.user_attr[u_id - 1]\n",
    "        i_attr = self.item_attr[i_id - 1]\n",
    "\n",
    "        x = torch.column_stack((u_id, i_id, u_attr, i_attr))\n",
    "        y = torch.tensor([1] + [0] * self.neg_sampl)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def _approx_neg_sampl(self):\n",
    "        neg_i_id = torch.randint(low=0, high=self.n_items, size=(self.neg_sampl,))\n",
    "        return neg_i_id\n",
    "\n",
    "#@timer\n",
    "def collate_fn(batch):\n",
    "    xs, ys = [], []\n",
    "    for x, y in batch:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = torch.cat(xs)\n",
    "    ys = torch.cat(ys).to(torch.float)\n",
    "    return xs, ys.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8d8d8c-9497-4114-be44-dd32bf945e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, print_loss=500):\n",
    "    model.train()\n",
    "    batch_size = train_loader.batch_size\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.\n",
    "        preds, ground_truths = [], []\n",
    "        for i_batch, (batch, y_true) in enumerate(tqdm(train_loader)):\n",
    "            batch, y_true = batch.to(device), y_true.to(device)\n",
    "            \n",
    "            y_pred = model(batch)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            preds.append(y_pred)\n",
    "            ground_truths.append(y_true)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if not ((i_batch+1) % print_loss):\n",
    "                pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "                ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "                last_loss = running_loss / print_loss\n",
    "                \n",
    "                train_roc_auc = roc_auc_score(ground_truth, pred)\n",
    "                test_loss, test_roc_auc = test()\n",
    "                \n",
    "                preds, ground_truths = [], []\n",
    "                running_loss = 0.\n",
    "                \n",
    "                print(f\"\"\"batch <{i_batch}>\\ntrain_loss: {last_loss} - train_roc_auc: {train_roc_auc}\\n\n",
    "            test_loss: {test_loss} - test_roc_auc: {test_roc_auc}\\n\"\"\")\n",
    "        print(f\"Epoch: {epoch}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fe1404-56ce-43ef-ab95-3f14700e5ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4773"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d79f0cd-9f28-498a-b764-cf0fb3117f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    batch_size = val_loader.batch_size\n",
    "    \n",
    "    running_loss = 0.\n",
    "    preds, ground_truths = [], []\n",
    "\n",
    "    for i_batch, (batch, y_true) in enumerate(val_loader):\n",
    "        batch, y_true = batch.to(device), y_true.to(device)\n",
    "        \n",
    "        y_pred = model(batch)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        \n",
    "        preds.append(y_pred)\n",
    "        ground_truths.append(y_true)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    pred = torch.cat(preds, dim=0).sigmoid().cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    \n",
    "    test_loss = running_loss / len(val_loader)\n",
    "    test_score = roc_auc_score(ground_truth, pred)\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b51a3b-c3d8-46ef-8d91-2656251f5ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milosz\\thesis-recsys\\src\\features\\features.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor([x.iloc[self.pad_index[0]:self.pad_index[1]].values])\n"
     ]
    }
   ],
   "source": [
    "feature_store = FeatureStore(scheme_relations, scheme_items, scheme_users, emb_dims={\"sparse\": 4, \"varlen\": 4})\n",
    "train_dataset = DeepFMDataset(feature_store, train_set.T, user_attr, item_attr, neg_sampl=2)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1024, collate_fn=collate_fn, drop_last=True)\n",
    "val_dataset = DeepFMDataset(feature_store, valid_set.T, user_attr, item_attr, neg_sampl=2)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=1024, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "model = DeepFM(feature_store, hidden_dim=[128, 64], device=device)\n",
    "#model = NCF(feature_store, hidden_dim=[64, 32, 8])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42106db4-3626-44c7-b088-4fa4fd1144c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.RMSprop(params=model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8eb32f-d71d-40f9-8be7-6b81f66bec53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████████▎                                                                                                                                                                                                      | 500/4773 [02:46<23:08:26, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <499>\n",
      "train_loss: 1.6017923901081086 - train_roc_auc: 0.5572694701013563\n",
      "test_loss: 1.3073567115300075 - test_roc_auc: 0.5838225361327352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████████████████████████████▎                                                                                                                                                                              | 1000/4773 [05:26<19:44:11, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <999>\n",
      "train_loss: 1.1292995933294296 - train_roc_auc: 0.6186290069379805\n",
      "test_loss: 1.0728814634384136 - test_roc_auc: 0.6114129514450659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1500/4773 [08:09<17:07:01, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <1499>\n",
      "train_loss: 0.9474802742004395 - train_roc_auc: 0.6675023461818695\n",
      "test_loss: 1.0012300589355811 - test_roc_auc: 0.6273348223664753\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2000/4773 [10:51<14:32:36, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <1999>\n",
      "train_loss: 0.8697934436798096 - train_roc_auc: 0.6959614947080613\n",
      "test_loss: 0.9624752487051543 - test_roc_auc: 0.6439883755758252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                         | 2500/4773 [13:32<11:43:58, 18.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <2499>\n",
      "train_loss: 0.8276030224561691 - train_roc_auc: 0.7127654760389327\n",
      "test_loss: 0.9196715083732424 - test_roc_auc: 0.6600111706412006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 3000/4773 [16:21<9:32:02, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <2999>\n",
      "train_loss: 0.7987688119411469 - train_roc_auc: 0.7268725374937058\n",
      "test_loss: 0.8946909298546506 - test_roc_auc: 0.6740027577396522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3500/4773 [19:10<7:04:15, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <3499>\n",
      "train_loss: 0.7752249270677567 - train_roc_auc: 0.7392818189430237\n",
      "test_loss: 0.8676207319820096 - test_roc_auc: 0.6876273788530998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 4000/4773 [21:53<4:05:28, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <3999>\n",
      "train_loss: 0.7577799472808838 - train_roc_auc: 0.7506435973100664\n",
      "test_loss: 0.8608747289926519 - test_roc_auc: 0.6971701722025553\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4500/4773 [24:36<1:26:20, 18.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <4499>\n",
      "train_loss: 0.7369563271999359 - train_roc_auc: 0.761811576057434\n",
      "test_loss: 0.8318601243586337 - test_roc_auc: 0.7118217802409739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4773/4773 [25:32<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████████▎                                                                                                                                                                                                      | 500/4773 [02:53<22:56:35, 19.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <499>\n",
      "train_loss: 0.7001673009395599 - train_roc_auc: 0.7797905407552719\n",
      "test_loss: 0.8219157995488406 - test_roc_auc: 0.723562723628348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████████████████████████████████▎                                                                                                                                                                              | 1000/4773 [05:41<21:01:05, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <999>\n",
      "train_loss: 0.6883850592374802 - train_roc_auc: 0.7873120420970916\n",
      "test_loss: 0.7929523026491229 - test_roc_auc: 0.7354111212828965\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1500/4773 [08:31<17:48:21, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <1499>\n",
      "train_loss: 0.6765607554912567 - train_roc_auc: 0.7950249957380294\n",
      "test_loss: 0.7842931063113054 - test_roc_auc: 0.742299283356233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2000/4773 [11:30<16:24:02, 21.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <1999>\n",
      "train_loss: 0.666683631658554 - train_roc_auc: 0.8013317189378737\n",
      "test_loss: 0.7800907203795221 - test_roc_auc: 0.7480552562971979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                         | 2500/4773 [14:17<12:32:52, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <2499>\n",
      "train_loss: 0.6567219982147217 - train_roc_auc: 0.8070399279527665\n",
      "test_loss: 0.7717757891704686 - test_roc_auc: 0.7540412054360494\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 3000/4773 [17:08<9:50:40, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <2999>\n",
      "train_loss: 0.6513308881521225 - train_roc_auc: 0.8114287125988007\n",
      "test_loss: 0.7816914399794492 - test_roc_auc: 0.7555667267974362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3500/4773 [20:11<7:28:40, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <3499>\n",
      "train_loss: 0.6420068746805191 - train_roc_auc: 0.8162300709457397\n",
      "test_loss: 0.7719653811641214 - test_roc_auc: 0.7607082840055981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 4000/4773 [23:02<4:17:30, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <3999>\n",
      "train_loss: 0.6370629956722259 - train_roc_auc: 0.820142881263733\n",
      "test_loss: 0.7674189036208872 - test_roc_auc: 0.7644312646183851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4500/4773 [25:58<1:33:24, 20.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <4499>\n",
      "train_loss: 0.6320764361619949 - train_roc_auc: 0.8227459668140412\n",
      "test_loss: 0.7708887173242479 - test_roc_auc: 0.7678120175514557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4773/4773 [26:56<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████████▎                                                                                                                                                                                                      | 500/4773 [02:47<22:54:59, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch <499>\n",
      "train_loss: 0.6156580771207809 - train_roc_auc: 0.829132550693512\n",
      "test_loss: 0.7572749440703912 - test_roc_auc: 0.771498535213915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████████████████▌                                                                                                                                                                                              | 732/4773 [03:36<19:53,  3.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(n_epochs, print_loss)\u001b[0m\n\u001b[0;32m      6\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m      7\u001b[0m preds, ground_truths \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_batch, (batch, y_true) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[0;32m      9\u001b[0m     batch, y_true \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device), y_true\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(batch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\thesis-recsys-EfbEvqEX-py3.10\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\thesis-recsys-EfbEvqEX-py3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\thesis-recsys-EfbEvqEX-py3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\thesis-recsys-EfbEvqEX-py3.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\thesis-recsys-EfbEvqEX-py3.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[16], line 26\u001b[0m, in \u001b[0;36mDeepFMDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m i_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_attr[i_id \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcolumn_stack((u_id, i_id, u_attr, i_attr))\n\u001b[1;32m---> 26\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_sampl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(n_epochs=10, print_loss=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7372b8f-3328-4d4f-a27d-bee6c00f76cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10dd7dd4-b196-4540-8eef-843f90ef523c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(path):\n",
    "    model = DeepFM(feature_store, hidden_dim=[128, 64], device=device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3819672-0ed1-4ab9-bd16-076184652243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model(model, \"models/deepfm_02.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd189a9-8169-4bdf-b78a-9644f762fb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = load_model(\"models/deepfm_02.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a75cfc3-410b-445f-b462-c5553a69510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFM(\n",
       "  (V): EmbeddingNet(\n",
       "    (embeddings): ModuleDict(\n",
       "      (user_id): Embedding(3066722, 4, padding_idx=0)\n",
       "      (app_id): Embedding(1232, 4, padding_idx=0)\n",
       "      (win): Embedding(2, 4, padding_idx=0)\n",
       "      (mac): Embedding(3, 4, padding_idx=0)\n",
       "      (linux): Embedding(3, 4, padding_idx=0)\n",
       "      (steam_deck): Embedding(2, 4, padding_idx=0)\n",
       "      (rating): Embedding(6, 4, padding_idx=0)\n",
       "      (tags): Embedding(416, 4, padding_idx=0)\n",
       "    )\n",
       "  )\n",
       "  (fm): FM()\n",
       "  (dnn): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=38, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d8657af-5cf3-4b26-bc41-c9c5188bc0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    bool_2d = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v]).astype(bool)\n",
    "    \n",
    "    prec_k = (reco_relevance.getA().sum(axis=1, where=bool_2d) / v).mean()\n",
    "    return prec_k\n",
    "\n",
    "# def mean_average_prec(reco_relevance):\n",
    "#     K = reco_relevance.shape[1]\n",
    "    \n",
    "#     mean_ap = 0.0\n",
    "#     for k in range(1, K+1):\n",
    "#         mean_ap += prec_k(reco_relevance[:, :k]) # DODAC MNOŻNIK 1/0 GDY ITEM JEST RELEWANTNY!!!\n",
    "#     return mean_ap / K\n",
    "\n",
    "def recall_k(reco_relevance, relevance, k=10):\n",
    "    sum_relevant = relevance.sum(axis=1)\n",
    "    return (reco_relevance.sum(axis=1) / sum_relevant).mean()\n",
    "\n",
    "def ndcg_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    ideal_relevance = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v])\n",
    "    \n",
    "    discount = 1 / np.log2(np.arange(2, k+2))\n",
    "    idcg = (ideal_relevance * discount).sum(axis=1)\n",
    "    dcg = (reco_relevance * discount).sum(axis=1)\n",
    "    ndcg = (dcg / idcg).mean()\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_embeddings(model, data):\n",
    "    pass\n",
    "\n",
    "@torch.no_grad()\n",
    "def recommend_k(user_emb, item_emb, past_interactions=None, k=10, user_batch_size=1000):\n",
    "    def remove_past_interactions(prob, user_batch):\n",
    "        id_x = np.repeat(np.arange(user_batch.shape[0]), np.diff(past_interactions[user_batch].indptr))\n",
    "        id_y = past_interactions[user_batch].indices\n",
    "        prob[id_x, id_y] = -torch.inf\n",
    "        return prob\n",
    "    \n",
    "    recommended_batches = []\n",
    "    user_batches = torch.arange(user_emb.shape[0]).split(user_batch_size)\n",
    "    for user_batch in user_batches:\n",
    "        prob = (user_emb[user_batch] @ item_emb.T).sigmoid()\n",
    "        prob = remove_past_interactions(prob, user_batch)\n",
    "        recommended_batches.append(prob.topk(k, 1)[1])\n",
    "    \n",
    "    recommendations = torch.cat(recommended_batches, 0)\n",
    "    return recommendations\n",
    "\n",
    "def recommendation_relevance(recommendations, ground_truth):\n",
    "    \"\"\"\n",
    "    Computes the relevance matrix of recommended items based on ground truth data.\n",
    "\n",
    "    This function takes a matrix of recommended items and a ground truth sparse matrix, and calculates\n",
    "    binary relevance of recommended items for each user. The relevance is determined by\n",
    "    comparing the recommended items with the actual items in the ground truth.\n",
    "\n",
    "    Args:\n",
    "        recommendations (numpy.ndarray): A 2D matrix of shape (n_users, k) where k is the number of \n",
    "            recommended items per user. Each row contains indices representing the recommended \n",
    "            items for a user.\n",
    "        ground_truth (scipy.csr_matrix): A sparse matrix of shape (n_users, n_items). The matrix \n",
    "            contains binary values indicating whether an item is relevant (1) or not (0) for each user.\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrix: A 2D matrix of shape (n_users, k) containing the relevance scores of the\n",
    "        recommended items for each user.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions of 'recommendations' and 'ground_truth' do not match or\n",
    "            are incompatible for matrix operations.\n",
    "    \"\"\"\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    k = recommendations.shape[1]\n",
    "    \n",
    "    if recommendations.shape[0] != n_users:\n",
    "        raise ValueError(\"Number of users in 'recommendations' should match 'ground_truth'.\")\n",
    "    \n",
    "    user_idx = np.repeat(np.arange(n_users), k)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, k))  # get values under arrays of indices \n",
    "                                                                        # (user_idx and item_idx) from ground truth\n",
    "    relevance_mask = np.asarray((ground_truth.sum(axis=1) != 0)).ravel()\n",
    "    \n",
    "    return relevance, relevance_mask\n",
    "\n",
    "def evaluate_nn(model, mp_matrix, val_matrix, k):\n",
    "    x_emb = generate_embeddings(model, val_data)\n",
    "    recommendations = recommend_k(x_emb['user'], x_emb['app'], past_interactions=mp_matrix, \n",
    "                                  k=10, user_batch_size=10000).cpu().numpy()\n",
    "    reco_relevance, relevance_mask = recommendation_relevance(recommendations, val_matrix)\n",
    "    \n",
    "    prec_k = precision_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    rec_k = recall_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    n_k = ndcg_k(reco_relevance[relevance_mask].getA(), val_matrix[relevance_mask], k)\n",
    "\n",
    "    return {f\"precision@{k}\": prec_k, f\"recall@{k}\": rec_k, f\"ndcg@{k}\": n_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37f523f1-b3fa-47c6-9eb3-ee57348cc1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, x):\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "    \n",
    "    return y.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7439363b-20e2-4a45-b772-a0249271a0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "past_interactions = mp_matrix\n",
    "def remove_past_interactions(prob, user_batch):\n",
    "    id_x = np.repeat(np.arange(user_batch.shape[0]), np.diff(past_interactions[user_batch].indptr))\n",
    "    id_y = past_interactions[user_batch].indices\n",
    "    prob[id_x, id_y] = -torch.inf\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74263268-297c-43c0-8a83-86272f187325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20ef4f24-3c12-4305-96c4-ffdafa2a256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_batches = []\n",
    "user_batches = (torch.arange(3066721) + 1).split(1000)\n",
    "item_batches = (torch.arange(1231) + 1).repeat(1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51eec6-160e-429d-872c-f05a93e71389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for user_batch in tqdm(user_batches):\n",
    "#     X = torch.cat([user_batch.repeat(1231, 1).t().reshape(-1, 1), item_tensor], dim=1)\n",
    "#     prob = evaluate(model, X)\n",
    "#     prob = prob.view(1000, -1)\n",
    "#     prob = remove_past_interactions(prob, user_batch)\n",
    "#     recommended_batches.append(prob.topk(10, 1)[1])\n",
    "    \n",
    "# recommendations = torch.cat(recommended_batches, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82d00f-a49b-416c-9644-ae9cb9170328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede86748-35de-4d84-a8ba-f85d868184ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco_env import RecoEnv\n",
    "from utils import import_data_for_env\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05327d09-72eb-49c7-b89a-855d078c9bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(RecoEnv.id, **import_data_for_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e172d7-f8dc-47c9-afd4-7e41ffac982f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d11e8-775d-4c6b-aa99-898b13d1c969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc = rec.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ceea8a-8ecd-45db-b28f-162cfcfe12f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005e4e0-c465-40ee-b22e-a4e54b14173b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc[vc >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d749a-43b7-4454-bd1e-b3e543020504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cb107-3281-40c0-9037-fed34a026384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
