{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a88688-5214-4ead-a060-4df9633efd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"../../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f0f27-4278-4c12-845c-2655b9edcad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import operator\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from models import NCF, DeepFM\n",
    "from features.store import FeatureStore\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6ccb1-bebd-4890-adb6-64417a22ed65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf866f5-a4f6-46bf-aa40-3fc38e3d5e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/steam/data.pkl\", \"rb\") as f:\n",
    "    data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde4358-ccb4-43cb-83fc-a3f4a6b76ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = data['relations_datastore'].dataframe.train.values.T\n",
    "supervision_set = data['relations_datastore'].dataframe.supervision.values.T\n",
    "valid_set = data['relations_datastore'].dataframe.valid.values.T\n",
    "item_attr = data['items_datastore'].dataframe.df\n",
    "user_attr = data['users_datastore'].dataframe.df\n",
    "\n",
    "scheme_relations = data['relations_datastore'].scheme\n",
    "scheme_items = data['items_datastore'].scheme\n",
    "scheme_users = data['users_datastore'].scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb8cb8-e9f7-454f-a251-140accc5109c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/steam/matrix.pkl\", \"rb\") as f:\n",
    "    matrix = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7587b6d6-5aac-4457-bbd7-a3e7e1275347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_matrix = matrix['train_csr']\n",
    "val_matrix = matrix['valid_csr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec240adc-0d43-4a65-b58c-16f2e5174f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scaler_user = StandardScaler()\n",
    "# user_attr_preprocess = scaler_user.fit_transform(user_attr)\n",
    "\n",
    "# scaler_item = StandardScaler()\n",
    "# item_attr_preprocess = np.copy(item_attr)\n",
    "# item_attr_preprocess[:, 435:] = scaler_item.fit_transform(item_attr[:, 435:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfa3ae-faa4-4a05-b55c-bb529685fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"Print the runtime of the decorated function\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_timer(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        run_time = end_time - start_time\n",
    "        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\")\n",
    "        return value\n",
    "    return wrapper_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31739385-daee-4693-ad46-180eb9c775d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepFMDataset(Dataset):\n",
    "    def __init__(self, feature_store, edge_index, user_attr, item_attr, neg_sampl):\n",
    "        self.edge_index = torch.tensor(edge_index) + 1\n",
    "        self.user_attr = torch.tensor(user_attr.values)\n",
    "        self.item_attr = feature_store.attr2tensor(item_attr, scheme='item_feat')\n",
    "        \n",
    "        self.users = self.edge_index[:, 0]\n",
    "        self.items = self.edge_index[:, 1]\n",
    "\n",
    "        self.n_users = self.user_attr.shape[0]\n",
    "        self.n_items = self.item_attr.shape[0]\n",
    "\n",
    "        self.neg_sampl = neg_sampl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.edge_index.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        u_id = self.users[idx].repeat(self.neg_sampl + 1)\n",
    "        i_id = torch.cat([self.items[idx].unsqueeze(0), self._approx_neg_sampl()])\n",
    "        \n",
    "        u_attr = self.user_attr[u_id - 1]\n",
    "        i_attr = self.item_attr[i_id - 1]\n",
    "\n",
    "        x = torch.column_stack((u_id, i_id, u_attr, i_attr))\n",
    "        y = torch.tensor([1] + [0] * self.neg_sampl)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def _approx_neg_sampl(self):\n",
    "        neg_i_id = torch.randint(low=0, high=self.n_items, size=(self.neg_sampl,))\n",
    "        return neg_i_id\n",
    "\n",
    "#@timer\n",
    "def collate_fn(batch):\n",
    "    xs, ys = [], []\n",
    "    for x, y in batch:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = torch.cat(xs)\n",
    "    ys = torch.cat(ys).to(torch.float)\n",
    "    return xs, ys.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d8d8c-9497-4114-be44-dd32bf945e29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(n_epochs, print_loss=500):\n",
    "    model.train()\n",
    "    batch_size = train_loader.batch_size\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.\n",
    "        preds, ground_truths = [], []\n",
    "        for i_batch, (batch, y_true) in enumerate(tqdm(train_loader)):\n",
    "            batch, y_true = batch.to(device), y_true.to(device)\n",
    "            \n",
    "            y_pred = model(batch)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            preds.append(y_pred)\n",
    "            ground_truths.append(y_true)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if not ((i_batch+1) % print_loss):\n",
    "                pred = torch.cat(preds, dim=0).detach().sigmoid().cpu().numpy()\n",
    "                ground_truth = torch.cat(ground_truths, dim=0).detach().cpu().numpy()\n",
    "                last_loss = running_loss / print_loss\n",
    "                \n",
    "                train_roc_auc = roc_auc_score(ground_truth, pred)\n",
    "                test_loss, test_roc_auc = test()\n",
    "                \n",
    "                preds, ground_truths = [], []\n",
    "                running_loss = 0.\n",
    "                \n",
    "                print(f\"\"\"batch <{i_batch}>\\ntrain_loss: {last_loss} - train_roc_auc: {train_roc_auc}\\n\n",
    "            test_loss: {test_loss} - test_roc_auc: {test_roc_auc}\\n\"\"\")\n",
    "        print(f\"Epoch: {epoch}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79f0cd-9f28-498a-b764-cf0fb3117f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    batch_size = val_loader.batch_size\n",
    "    \n",
    "    running_loss = 0.\n",
    "    preds, ground_truths = [], []\n",
    "\n",
    "    for i_batch, (batch, y_true) in enumerate(val_loader):\n",
    "        batch, y_true = batch.to(device), y_true.to(device)\n",
    "        \n",
    "        y_pred = model(batch)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        \n",
    "        preds.append(y_pred)\n",
    "        ground_truths.append(y_true)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    pred = torch.cat(preds, dim=0).sigmoid().cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    \n",
    "    test_loss = running_loss / len(val_loader)\n",
    "    test_score = roc_auc_score(ground_truth, pred)\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b51a3b-c3d8-46ef-8d91-2656251f5ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_store = FeatureStore(scheme_relations, scheme_items, scheme_users, emb_dims={\"sparse\": 4, \"varlen\": 4})\n",
    "train_dataset = DeepFMDataset(feature_store, train_set.T, user_attr, item_attr, neg_sampl=2)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=1024, collate_fn=collate_fn, drop_last=True)\n",
    "val_dataset = DeepFMDataset(feature_store, valid_set.T, user_attr, item_attr, neg_sampl=2)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=1024, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "model = DeepFM(feature_store, hidden_dim=[128, 64], device=device)\n",
    "#model = NCF(feature_store, hidden_dim=[64, 32, 8])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42106db4-3626-44c7-b088-4fa4fd1144c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.RMSprop(params=model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8eb32f-d71d-40f9-8be7-6b81f66bec53",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(n_epochs=10, print_loss=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7372b8f-3328-4d4f-a27d-bee6c00f76cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd7dd4-b196-4540-8eef-843f90ef523c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(path):\n",
    "    model = DeepFM(feature_store, hidden_dim=[128, 64], device=device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3819672-0ed1-4ab9-bd16-076184652243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model(model, \"models/deepfm_02.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd189a9-8169-4bdf-b78a-9644f762fb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = load_model(\"models/deepfm_02.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75cfc3-410b-445f-b462-c5553a69510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8657af-5cf3-4b26-bc41-c9c5188bc0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    bool_2d = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v]).astype(bool)\n",
    "    \n",
    "    prec_k = (reco_relevance.getA().sum(axis=1, where=bool_2d) / v).mean()\n",
    "    return prec_k\n",
    "\n",
    "# def mean_average_prec(reco_relevance):\n",
    "#     K = reco_relevance.shape[1]\n",
    "    \n",
    "#     mean_ap = 0.0\n",
    "#     for k in range(1, K+1):\n",
    "#         mean_ap += prec_k(reco_relevance[:, :k]) # DODAC MNOŻNIK 1/0 GDY ITEM JEST RELEWANTNY!!!\n",
    "#     return mean_ap / K\n",
    "\n",
    "def recall_k(reco_relevance, relevance, k=10):\n",
    "    sum_relevant = relevance.sum(axis=1)\n",
    "    return (reco_relevance.sum(axis=1) / sum_relevant).mean()\n",
    "\n",
    "def ndcg_k(reco_relevance, relevance, k=10):\n",
    "    v = np.asarray(relevance.sum(axis=1).flatten(), dtype=int)[0].clip(1, k)\n",
    "    ideal_relevance = np.vstack([np.concatenate((np.ones(i), np.zeros(k - i))) for i in v])\n",
    "    \n",
    "    discount = 1 / np.log2(np.arange(2, k+2))\n",
    "    idcg = (ideal_relevance * discount).sum(axis=1)\n",
    "    dcg = (reco_relevance * discount).sum(axis=1)\n",
    "    ndcg = (dcg / idcg).mean()\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_embeddings(model, data):\n",
    "    pass\n",
    "\n",
    "@torch.no_grad()\n",
    "def recommend_k(user_emb, item_emb, past_interactions=None, k=10, user_batch_size=1000):\n",
    "    def remove_past_interactions(prob, user_batch):\n",
    "        id_x = np.repeat(np.arange(user_batch.shape[0]), np.diff(past_interactions[user_batch].indptr))\n",
    "        id_y = past_interactions[user_batch].indices\n",
    "        prob[id_x, id_y] = -torch.inf\n",
    "        return prob\n",
    "    \n",
    "    recommended_batches = []\n",
    "    user_batches = torch.arange(user_emb.shape[0]).split(user_batch_size)\n",
    "    for user_batch in user_batches:\n",
    "        prob = (user_emb[user_batch] @ item_emb.T).sigmoid()\n",
    "        prob = remove_past_interactions(prob, user_batch)\n",
    "        recommended_batches.append(prob.topk(k, 1)[1])\n",
    "    \n",
    "    recommendations = torch.cat(recommended_batches, 0)\n",
    "    return recommendations\n",
    "\n",
    "def recommendation_relevance(recommendations, ground_truth):\n",
    "    \"\"\"\n",
    "    Computes the relevance matrix of recommended items based on ground truth data.\n",
    "\n",
    "    This function takes a matrix of recommended items and a ground truth sparse matrix, and calculates\n",
    "    binary relevance of recommended items for each user. The relevance is determined by\n",
    "    comparing the recommended items with the actual items in the ground truth.\n",
    "\n",
    "    Args:\n",
    "        recommendations (numpy.ndarray): A 2D matrix of shape (n_users, k) where k is the number of \n",
    "            recommended items per user. Each row contains indices representing the recommended \n",
    "            items for a user.\n",
    "        ground_truth (scipy.csr_matrix): A sparse matrix of shape (n_users, n_items). The matrix \n",
    "            contains binary values indicating whether an item is relevant (1) or not (0) for each user.\n",
    "\n",
    "    Returns:\n",
    "        numpy.matrix: A 2D matrix of shape (n_users, k) containing the relevance scores of the\n",
    "        recommended items for each user.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the dimensions of 'recommendations' and 'ground_truth' do not match or\n",
    "            are incompatible for matrix operations.\n",
    "    \"\"\"\n",
    "    n_users, n_items = ground_truth.shape\n",
    "    k = recommendations.shape[1]\n",
    "    \n",
    "    if recommendations.shape[0] != n_users:\n",
    "        raise ValueError(\"Number of users in 'recommendations' should match 'ground_truth'.\")\n",
    "    \n",
    "    user_idx = np.repeat(np.arange(n_users), k)\n",
    "    item_idx = recommendations.flatten()\n",
    "    relevance = ground_truth[user_idx, item_idx].reshape((n_users, k))  # get values under arrays of indices \n",
    "                                                                        # (user_idx and item_idx) from ground truth\n",
    "    relevance_mask = np.asarray((ground_truth.sum(axis=1) != 0)).ravel()\n",
    "    \n",
    "    return relevance, relevance_mask\n",
    "\n",
    "def evaluate_nn(model, mp_matrix, val_matrix, k):\n",
    "    x_emb = generate_embeddings(model, val_data)\n",
    "    recommendations = recommend_k(x_emb['user'], x_emb['app'], past_interactions=mp_matrix, \n",
    "                                  k=10, user_batch_size=10000).cpu().numpy()\n",
    "    reco_relevance, relevance_mask = recommendation_relevance(recommendations, val_matrix)\n",
    "    \n",
    "    prec_k = precision_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    rec_k = recall_k(reco_relevance[relevance_mask], val_matrix[relevance_mask], k)\n",
    "    n_k = ndcg_k(reco_relevance[relevance_mask].getA(), val_matrix[relevance_mask], k)\n",
    "\n",
    "    return {f\"precision@{k}\": prec_k, f\"recall@{k}\": rec_k, f\"ndcg@{k}\": n_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f523f1-b3fa-47c6-9eb3-ee57348cc1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, x):\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    y = model(x)\n",
    "    \n",
    "    return y.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439363b-20e2-4a45-b772-a0249271a0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "past_interactions = mp_matrix\n",
    "def remove_past_interactions(prob, user_batch):\n",
    "    id_x = np.repeat(np.arange(user_batch.shape[0]), np.diff(past_interactions[user_batch].indptr))\n",
    "    id_y = past_interactions[user_batch].indices\n",
    "    prob[id_x, id_y] = -torch.inf\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74263268-297c-43c0-8a83-86272f187325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef4f24-3c12-4305-96c4-ffdafa2a256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_batches = []\n",
    "user_batches = (torch.arange(3066721) + 1).split(1000)\n",
    "item_batches = (torch.arange(1231) + 1).repeat(1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51eec6-160e-429d-872c-f05a93e71389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for user_batch in tqdm(user_batches):\n",
    "#     X = torch.cat([user_batch.repeat(1231, 1).t().reshape(-1, 1), item_tensor], dim=1)\n",
    "#     prob = evaluate(model, X)\n",
    "#     prob = prob.view(1000, -1)\n",
    "#     prob = remove_past_interactions(prob, user_batch)\n",
    "#     recommended_batches.append(prob.topk(10, 1)[1])\n",
    "    \n",
    "# recommendations = torch.cat(recommended_batches, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82d00f-a49b-416c-9644-ae9cb9170328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede86748-35de-4d84-a8ba-f85d868184ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco_env import RecoEnv\n",
    "from utils import import_data_for_env\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05327d09-72eb-49c7-b89a-855d078c9bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(RecoEnv.id, **import_data_for_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e172d7-f8dc-47c9-afd4-7e41ffac982f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d11e8-775d-4c6b-aa99-898b13d1c969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc = rec.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ceea8a-8ecd-45db-b28f-162cfcfe12f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005e4e0-c465-40ee-b22e-a4e54b14173b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc[vc >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d749a-43b7-4454-bd1e-b3e543020504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10cb107-3281-40c0-9037-fed34a026384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
